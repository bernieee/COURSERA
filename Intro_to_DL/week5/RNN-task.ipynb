{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GDF3HAxuuNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "7aa60080-331c-4c76-e368-4a879ba2fd95"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()  # change to the week you're working on\n",
        "# note on week 2: select setup_week2_v2() if you've started the course after August 13, 2018,\n",
        "# otherwise call setup_week2().\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 12:56:47--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-24 12:56:47 (58.7 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdRbDQHvu2fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmrVDMyUuWWt",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "AjIcnY2uuWWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07ce62cf-a248-421d-f870-488548f51906"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-eeMsRtuWWz",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "V9rFAMUUuWWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "5NGMUrPfuWW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "da9ef62b-93d2-4135-faeb-2bb9df306aa9"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "-B7jocpVuWW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8316bcf3-7edd-4ede-cf7c-42ae4745a117"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvjPBGAfuWXA",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "0GwHN-WMuWXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f18e630d-ea4d-4993-947e-2d74ce8f2db3"
      },
      "source": [
        "tokens = set(''.join(names))\n",
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens.add(pad_token)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiO71fUuWXE",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "SwLSXjQtuWXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {symbol : index for symbol,index in zip(tokens,range(len(tokens)))}\n",
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "JQeb70PwuWXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "7Tee_P7BuWXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "0538eb7d-482a-46f1-d176-c6e3ae277654"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[32 48 18  9 47  9  5  1 26]\n",
            " [32 34  1  6 19 12 26 26 26]\n",
            " [32 35 19  8 36 36  8  5 26]\n",
            " [32 34  8  6 49  9 37 37  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V7tJb4guWXR",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/bernieee/COURSERA/blob/master/Intro_to_DL/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "6tA6Vs-ouWXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "56fdfd1c-0689-4a8a-a722-489bfe78782b"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "iWj-vQtMuWXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu')\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(len(tokens), activation='softmax')\n",
        "### YOUR CODE HERE "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfb-fcZCuWXY",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/bernieee/COURSERA/blob/master/Intro_to_DL/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "BCjquXFxuWXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t], 1)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVpwqOghuWXe",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "8zZonx9yuWXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8yJKQ0GuWXi",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "6TkkOurFuWXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtvCCjPLuWXl",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "kHBGFz4wuWXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "2a0d3096-3d05-4b2c-d51e-c75ee42a0127"
      },
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5XP1bhEuWXq",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "i1DDr40FuWXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cffe81a8-034d-4687-f27a-2a109078df7f"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPT5ma6CuWXu",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "j92CMq1IuWXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "H3w-Mze4uWXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "eTCDTnkauWX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "60f8ec7d-b464-4f94-ff06-be1304016200"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Rarnea\n",
            " Meldets\n",
            " Kepfens\n",
            " Dasta\n",
            " Sarantan\n",
            " Gem\n",
            " Ay\n",
            " Tilllensy\n",
            " Doania\n",
            " Lumille\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "kdLxPmoLuWX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "19742597-374a-47dc-d488-4fac0c8f1637"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpte\n",
            " Trumpi\n",
            " Trumpal\n",
            " Trumpe\n",
            " Trumpe\n",
            " Trumpy\n",
            " Trumparre\n",
            " Trump\n",
            " Trumpeo\n",
            " Trump\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt85EM9AuWX9",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "k8dwsTPUuWX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"IiiifKjUXeYp9AfR\"\n",
        "COURSERA_EMAIL = \"Olya.Kolomyttseva@student.msu.ru\""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Zty8uOjduWYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8e21afca-6e33-4d46-b673-fa75b5406bad"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171_Y0u7uWYD",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f47jNernuWYD",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "kH-bYwxLuWYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "7c0c7894-e383-4942-fd0e-01a810c260da"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9msroJD7uWYH",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "iGy7Dme-uWYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "DeR-A54fuWYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}